{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "792f34d7-b085-4949-940b-0c3fe7cb9ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 02:55:36.591540: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-04 02:55:36.630331: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-04 02:55:37.201012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math \n",
    "from math import ceil\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from OneNucleotideIndexer import OneNucleotideIndexer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Masking,Reshape,GlobalAveragePooling1D, ZeroPadding1D,Lambda, Concatenate,Input, Dense, BatchNormalization, Conv1D, Flatten, Activation, Embedding, MaxPooling1D, SeparableConv1D, Conv1DTranspose\n",
    "from Metrics import specificity\n",
    "import tempfile\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f8da116-f455-459e-9c9a-60e403d03697",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_for_model_path = '/media/zakaria/spin/SayantanProteinFamily/Uniref_Uniprot/Data_for_model' #'/mnt/e/GenerativeAI_generated_sequences/Data'\n",
    "uniprotKB_file      = f'{Data_for_model_path}/uniprot_sprot.fasta'\n",
    "bacterium_fastafile = f'{Data_for_model_path}/positive.fasta'\n",
    "model_input_data = f'{Data_for_model_path}/uniref50_model_data/model_inputs'\n",
    "saved_model_path   = f'{Data_for_model_path}/Models'\n",
    "encoder_model_path = f'{saved_model_path}/network_classifier_features_20250217_091829.h5'\n",
    "save_csv           = '/media/zakaria/spin/SayantanProteinFamily/Uniref_Uniprot/Htmls_results/Autoencoder_varieties_result'\n",
    "indexer_file       = f'{model_input_data}/A_U_len1024_20250217_091829.pkl'\n",
    "\n",
    "min_len = 50\n",
    "max_len = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c990f712-c3e6-4148-beed-d92049ff7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fmatrix_embed = np.load(f'{model_input_data}/final_train_fmatrix_embedded_1024.npy')\n",
    "val_fmatrix_embed   = np.load(f'{model_input_data}/final_val_fmatrixEmbed_1024.npy')\n",
    "val1000_fmatrix_embed   = np.load(f'{model_input_data}/binned_final_val_fmatrixEmbed_1024.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621d02fb-629a-4587-bbcd-872f598467d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((757338, 1024, 3), (216382, 1024, 3), (1000, 1024, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fmatrix_embed.shape,val_fmatrix_embed.shape,val1000_fmatrix_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2805cd3-ad31-440e-a72f-7095efc7ad0e",
   "metadata": {},
   "source": [
    "# Embedding layer from pre-trained encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b0cc41-381e-44c1-ba41-29adf0766ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConvLayer(Layer):\n",
    "    def __init__(self, filter_num, filter_size, **kwargs):\n",
    "        super(CustomConvLayer, self).__init__(**kwargs)\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_size = filter_size\n",
    "        self.conv1 = Conv1D(filters=filter_num, kernel_size=filter_size, use_bias=True,  activation='relu', name='conv1')\n",
    "        self.conv2 = Conv1D(filters=filter_num, kernel_size=(2*filter_size)+1, use_bias=False, strides=2, name='conv2')# \n",
    "        self.bn = BatchNormalization(name='bn')\n",
    "        self.activation = Activation(activation='relu', name='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomConvLayer, self).get_config()\n",
    "        config.update({\n",
    "            'filter_num': self.filter_num,\n",
    "            'filter_size': self.filter_size\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def set_weights(self, weight_list):\n",
    "        self.conv1.set_weights(weight_list[:2])\n",
    "        self.conv2.set_weights(weight_list[2:3])\n",
    "        self.bn.set_weights(weight_list[3:])\n",
    "\n",
    "    def freeze_layers(self):\n",
    "        self.conv1.trainable = False\n",
    "        self.conv2.trainable = False\n",
    "        self.bn.trainable    = False\n",
    "\n",
    "    def unfreeze_layers(self):\n",
    "        self.conv1.trainable = True\n",
    "        self.conv2.trainable = True\n",
    "        self.bn.trainable    = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5b983c-a104-472d-988b-18eb92739b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 02:55:41.668103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13605 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "encoder_model = load_model(encoder_model_path, custom_objects={'CustomConvLayer': CustomConvLayer, 'specificity': specificity})\n",
    "embedding_layer = encoder_model.get_layer(name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f02aef4-afdf-4804-8945-14f5b055db21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_tensor (InputLayer)   [(None, 1024)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 1024, 3)           81        \n",
      "                                                                 \n",
      " custom_conv_layer (CustomC  (None, 508, 32)           7616      \n",
      " onvLayer)                                                       \n",
      "                                                                 \n",
      " custom_conv_layer_1 (Custo  (None, 250, 64)           35136     \n",
      " mConvLayer)                                                     \n",
      "                                                                 \n",
      " custom_conv_layer_2 (Custo  (None, 121, 128)          139904    \n",
      " mConvLayer)                                                     \n",
      "                                                                 \n",
      " custom_conv_layer_3 (Custo  (None, 57, 256)           558336    \n",
      " mConvLayer)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14592)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 741073 (2.83 MB)\n",
      "Trainable params: 740113 (2.82 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef179df5-5dd6-467a-9ecc-728360f601a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of the model: (None, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape of the model:\", encoder_model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31fbedd-7f81-4cf4-9165-29fa08836712",
   "metadata": {},
   "source": [
    "### Freeze all encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c996a7ab-43fa-4106-9377-e076a307226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in encoder_model.layers:\n",
    "    if isinstance(layer, CustomConvLayer):\n",
    "        layer.freeze_layers()\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d594d9-fb2a-4350-92a0-7d3904e3eb82",
   "metadata": {},
   "source": [
    "### Get the trained embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f53f60e-8cf6-4681-9a0f-2de697ce289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 27\n",
      "Embedding Dimension: 3\n",
      "\n",
      "Vocabulary and Embedding Values:\n",
      "\n",
      "Token ID 0: [-0.02140465  0.02830246 -0.05574557]\n",
      "Token ID 1: [ 0.01456194 -0.04204811  0.03270236]\n",
      "Token ID 2: [-0.06271231 -0.11801422 -0.05803983]\n",
      "Token ID 3: [ 0.07430171  0.29197326 -0.23212597]\n",
      "Token ID 4: [ 0.01646761  0.70462066 -0.6810645 ]\n",
      "Token ID 5: [-0.28561434  0.14610802 -0.00950604]\n",
      "Token ID 6: [-0.16307573 -0.5325746   0.07229828]\n",
      "Token ID 7: [0.5686764  0.1469355  0.09788614]\n",
      "Token ID 8: [-0.38822517  0.09971034 -0.5219342 ]\n",
      "Token ID 9: [-0.27956656  0.05687758  0.07124779]\n",
      "Token ID 10: [-0.34459665 -0.01498139 -0.14375386]\n",
      "Token ID 11: [-0.00147066 -0.21718769 -0.10160962]\n",
      "Token ID 12: [ 0.19393146 -0.26964355  0.35422647]\n",
      "Token ID 13: [ 0.45520952 -0.15856832  0.37196437]\n",
      "Token ID 14: [0.35017297 0.27239195 0.01043969]\n",
      "Token ID 15: [-0.08567002  0.08376089 -0.37251484]\n",
      "Token ID 16: [0.00457283 0.6379865  1.3526993 ]\n",
      "Token ID 17: [-0.00031182 -0.06125099  0.29761612]\n",
      "Token ID 18: [ 0.05393873  0.33711925 -0.25948238]\n",
      "Token ID 19: [0.17631109 0.03155163 0.13140036]\n",
      "Token ID 20: [-0.328657   -0.15513475  0.18860212]\n",
      "Token ID 21: [-0.31102023  0.83681464 -0.14026424]\n",
      "Token ID 22: [-0.13204028 -0.16283615  0.09040894]\n",
      "Token ID 23: [-0.06621552  0.00101196  0.13275206]\n",
      "Token ID 24: [-0.14839767 -0.18150882 -0.00911344]\n",
      "Token ID 25: [-0.23124418 -0.24583317  0.18549883]\n",
      "Token ID 26: [ 0.048637    0.02603648 -0.03089851]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = embedding_layer.get_weights()[0]\n",
    "# Display the vocabulary and their corresponding embedding values\n",
    "vocab_size, embedding_dim = embedding_matrix.shape\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"Embedding Dimension:\", embedding_dim)\n",
    "print(\"\\nVocabulary and Embedding Values:\\n\")\n",
    "\n",
    "for token_id in range(vocab_size):\n",
    "    print(f\"Token ID {token_id}: {embedding_matrix[token_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8063c4-b4ac-4110-9c58-6d457cb31cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vec1, vec2):\n",
    "    sum_squared_diff = 0\n",
    "    for i in range(len(vec1)):\n",
    "        diff = vec1[i] - vec2[i]\n",
    "        sum_squared_diff += diff * diff\n",
    "    return sum_squared_diff ** 0.5 # square root of the sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1488f1-4c58-4076-94d9-631a6ed5f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, to load the dictionary back:\n",
    "with open(indexer_file, \"rb\") as f:\n",
    "    new_index_table = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243d28c4-dc7b-4dee-b76a-5585882540c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 2,\n",
       " 'R': 3,\n",
       " 'H': 4,\n",
       " 'I': 5,\n",
       " 'E': 6,\n",
       " 'P': 7,\n",
       " 'G': 8,\n",
       " 'L': 9,\n",
       " 'V': 10,\n",
       " 'D': 11,\n",
       " 'Y': 12,\n",
       " 'W': 13,\n",
       " 'S': 14,\n",
       " 'Q': 15,\n",
       " 'M': 16,\n",
       " 'T': 17,\n",
       " 'F': 18,\n",
       " 'N': 19,\n",
       " 'K': 20,\n",
       " 'C': 21,\n",
       " 'U': 22}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_index_table.index_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7977797-310b-4ee6-bb97-5252194db929",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_letter = {}\n",
    "for letter, index in new_index_table.index_table.items():\n",
    "    index_to_letter[index] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ff628b-7c04-4020-b16f-33702a2b7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_to_letters(sample, embedding_matrix=embedding_matrix, type_of_seq = 'Original'):\n",
    "    recons_seq = []\n",
    "    for num,new_vector in enumerate(sample):\n",
    "        min_distance = float('inf')\n",
    "        closest_token = None\n",
    "        \n",
    "                                                                   # vocab_size, embedding_dim = embedding_matrix.shape\n",
    "        \n",
    "        for token_id in range(2,23):\n",
    "            vector = embedding_matrix[token_id]\n",
    "            distance = euclidean_distance(new_vector , vector)\n",
    "                                                                   # print(f'Distance of new vector from token {token_id}: {distance}')\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_token = token_id\n",
    "        recons_seq.append(index_to_letter[closest_token])\n",
    "                                                                   # print(f'Recons_Vector {i} closest match is token {closest_token} with distance {min_distance}')\n",
    "    \n",
    "    # Join the letters to form the tokenized string for the sequence.\n",
    "    recons_seq_str = \"\".join(recons_seq)\n",
    "        \n",
    "        # output the closest match \n",
    "    # print(f'Recons_Vector {i} closest match is token {closest_token} with distance {min_distance}')\n",
    "    # print(len(tokenized_seq))\n",
    "    # all_tokenized_seq.append(tokenized_seq)\n",
    "    \n",
    "    #print(f'{type_of_seq} sequence is : {recons_seq_str}\\n')\n",
    "    return recons_seq_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd83a43-a85b-4c7f-99c4-9fd63e5b8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_identity_score(output_file):\n",
    "    try:\n",
    "        with open(output_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if \"Identity:\" in line:  # Look for the line containing identity\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4:\n",
    "                        percentage = parts[-1]\n",
    "                        cleaned_score = percentage.strip('() ').replace('%', '')\n",
    "                        if cleaned_score:\n",
    "                            return float(cleaned_score)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading identity score: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb6f4748-04e8-4b41-b7cc-0e876a55b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_needle(seq1, seq2):\n",
    "    # Create temporary files for seq1 and seq2\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False, suffix=\".fasta\") as temp_seq1:\n",
    "        temp_seq1.write(f\">seq1\\n{seq1}\")\n",
    "        temp_seq1.flush()  # Ensure that the content is written to disk\n",
    "        temp_seq1_path = temp_seq1.name\n",
    "        # Read the content of temp_seq1 immediately after flushing to disk\n",
    "        # with open(temp_seq1_path, 'r') as f:\n",
    "        #     print(f\"Temporary file for seq1 (before running needle):\\n{f.read()}\")\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", delete=False, suffix=\".fasta\") as temp_seq2:\n",
    "        temp_seq2.write(f\">seq2\\n{seq2}\")\n",
    "        temp_seq2.flush()  # Ensure that the content is written to disk\n",
    "        temp_seq2_path = temp_seq2.name\n",
    "        # Read the content of temp_seq2 immediately after flushing to disk\n",
    "        # with open(temp_seq2_path, 'r') as f:\n",
    "        #     print(f\"Temporary file for seq2 (before running needle):\\n{f.read()}\")\n",
    "\n",
    "    # Temporary file for needle output\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_output:\n",
    "        temp_output_path = temp_output.name\n",
    "\n",
    "    try:\n",
    "        # Run needle and suppress standard output and error\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"needle\", #/projects/academic/mshalfon/hzgirgis/projects/sp_unsupervised/EMBOSS-6.6.0/emboss/\n",
    "                \"-asequence\", temp_seq1_path,\n",
    "                \"-bsequence\", temp_seq2_path,\n",
    "                \"-sprotein1\", \n",
    "                \"-sprotein2\", \n",
    "                \"-gapopen\", \"10\", \n",
    "                \"-gapextend\", \"0.5\", \n",
    "                \"-outfile\", temp_output_path\n",
    "            ],\n",
    "            check=True,\n",
    "            stdout=subprocess.PIPE,  # Suppress standard output\n",
    "            stderr=subprocess.PIPE   # Suppress standard error\n",
    "        )\n",
    "\n",
    "        # Print the contents of the output file to check\n",
    "        #with open(temp_output_path, 'r') as output_file:\n",
    "         #   needle_output = output_file.read()\n",
    "          #  print(\"Needle Output:\\n\", needle_output)  # Print the output for debugging\n",
    "\n",
    "        # Extract identity score from the output file\n",
    "        identity_score = extract_identity_score(temp_output_path)\n",
    "\n",
    "    finally:\n",
    "        # Clean up temporary files\n",
    "        os.remove(temp_seq1_path)\n",
    "        os.remove(temp_seq2_path)\n",
    "        os.remove(temp_output_path)\n",
    "\n",
    "    return identity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32dd4dc1-689b-4c29-b48f-66962b7d1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_masking(sample):\n",
    "    \n",
    "    # 1) build a boolean mask of shape (200,) that is True where all channels == 0\n",
    "    all_zero_mask = np.all(sample == 0, axis=0)\n",
    "    \n",
    "    # 2) find the indices where that happens\n",
    "    all_zero_indices = np.where(all_zero_mask)[0]\n",
    "    \n",
    "    # 3) grab the first one (if any)\n",
    "    if all_zero_indices.size > 0:\n",
    "        first_all_zero_index = all_zero_indices[0]\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        first_all_zero_index = None\n",
    "    return first_all_zero_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda0132-320a-4130-bcc6-8aadf07bf674",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356bfe0f-115f-4359-8416-72a58b5c4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, z_mean, z_log_var):\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        z_size = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch_size, z_size))  \n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon \n",
    "    def get_config(self):\n",
    "        # No extra args to serialize, just inherit base config\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0df59780-f702-446c-aeb9-e25c51db61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class MaskedZero(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaskedZero, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        \"\"\"\n",
    "        inputs: Tensor of shape (batch_size, max_len, features)\n",
    "        mask:   Boolean Tensor of shape (batch_size, max_len,) where False=masked\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            \n",
    "            mask = tf.cast(mask, inputs.dtype)   # where the mask values changes to 1s and 0s\n",
    "             \n",
    "            # expand mask dims so it broadcasts over the last axis which is the features\n",
    "            # e.g. mask shape (B, T) -> (B, T, 1) for inputs (B, T, F)\n",
    "            for _ in range(len(inputs.shape) - len(mask.shape)):                   #### \n",
    "                mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "            inputs  = inputs * mask\n",
    "            \n",
    "        return inputs\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # propagate the input mask unchanged\n",
    "        return mask\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MaskedZero, self).get_config()\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "169f2ed8-4fa6-41bf-b2ef-3fe0101833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class MaskedConv1D(keras.layers.Layer):\n",
    "    def __init__(self, filter_num, filter_size,strides,pool_size=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # self.supports_masking = True\n",
    "        self.filter_num  = filter_num\n",
    "        self.filter_size = filter_size\n",
    "        self.strides     = strides\n",
    "        self.pool_size   = pool_size\n",
    "        self.bn = BatchNormalization(name='bn')\n",
    "        self.activation = Activation(activation='relu', name='relu')\n",
    "        self.conv1 = Conv1D(filters=filter_num, kernel_size=filter_size, strides = strides, padding='same', name='conv1')\n",
    "        if pool_size is not None:\n",
    "            self.max_pool = MaxPooling1D(pool_size=pool_size, padding='valid', name='mask_pool')  # MaxPooling1D for the mask\n",
    "        else:\n",
    "            self.max_pool = None\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if self.max_pool is None:\n",
    "            return mask\n",
    "        if mask is not None:\n",
    "            if len(mask.shape) == 2:\n",
    "                mask = tf.expand_dims(mask, axis=-1)  \n",
    "                mask = tf.cast(mask, dtype=tf.float32)  \n",
    "            mask = self.max_pool(mask)\n",
    "            mask = tf.squeeze(mask, axis=-1)\n",
    "            return tf.cast(mask, tf.bool)   \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filter_num' :  self.filter_num,\n",
    "            'filter_size': self.filter_size,\n",
    "            'strides'    : self.strides,\n",
    "            'pool_size'  : self.pool_size,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "314bb58b-f1a6-4270-a4f1-7f9879a1462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class ExtractMask(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mask = tf.not_equal(inputs, 0.0)\n",
    "        mask = tf.reduce_any(mask, axis=-1)  # (batch, time)\n",
    "        return tf.cast(mask, tf.bool)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec8f6c0b-d29a-4917-9e61-0e653bda6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class AssertMaskedZeros(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "    def call(self, inputs, mask=None):\n",
    "        input_tensor, embedding_output = inputs\n",
    "        masked_positions = tf.where(tf.equal(input_tensor, 0))\n",
    "        masked_vecs = tf.gather_nd(embedding_output, masked_positions)\n",
    "        assert_op= tf.debugging.assert_near(\n",
    "            masked_vecs,\n",
    "            tf.zeros_like(masked_vecs),\n",
    "            message=\"Embedding outputs at masked positions should be zero!\"\n",
    "        )\n",
    "        # ensure the assert runs, but *then* return emb\n",
    "        # with tf.control_dependencies([assert_op]):\n",
    "        #     return tf.identity(embedding_output)\n",
    "        return embedding_output\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8721584-7246-4059-8d90-70bfb450dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampler = Sampling()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker]\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        # Encoder already masks internally and returns the original mask\n",
    "        z_mean, z_log_var, orig_mask = self.encoder(inputs) #, training=training\n",
    "        z = self.sampler(z_mean, z_log_var)\n",
    "        reconstruction = self.decoder([z, orig_mask]) # , training = training\n",
    "        return reconstruction\n",
    "    \n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            z_mean, z_log_var, orig_mask = self.encoder(data)#data[0] if dataloader returned input twice , training=True\n",
    "            z = self.sampler(z_mean, z_log_var)\n",
    "            reconstruction = self.decoder([z, orig_mask]) #, training=True\n",
    "            \n",
    "            # print(\"Train step recons shape: \",reconstruction.shape)\n",
    "            # mse = tf.keras.losses.MeanSquaredError(reduction=\"none\")\n",
    "            # loss_per_example = mse(data, reconstruction)  # shape: (batch,)\n",
    "            # reconstruction_loss = tf.reduce_mean(tf.reduce_sum(loss_per_example), axis=(1,2))\n",
    "            # reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(data, reconstruction),axis=(1, 2)))  \n",
    "            squared_error = tf.math.squared_difference(data, reconstruction)  # shape: (batch, 200, 3)\n",
    "            loss_per_example = tf.reduce_sum(squared_error, axis=[1, 2])       # shape: (batch,)\n",
    "            reconstruction_loss = tf.reduce_mean(loss_per_example) \n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            total_loss = (reconstruction_loss + tf.reduce_mean(kl_loss)) / (max_len * 3.0)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "        \n",
    "    def test_step(self, data):   # for validation loss calculation\n",
    "        \n",
    "        z_mean, z_log_var, orig_mask = self.encoder(data)#data[0] if dataloader returned input twice,training=False\n",
    "        z = self.sampler(z_mean, z_log_var)\n",
    "        reconstruction = self.decoder([z, orig_mask]) #,training=False\n",
    "        # mse = tf.keras.losses.MeanSquaredError(reduction=\"none\")\n",
    "        # loss_per_example = mse(data, reconstruction)  # shape: (batch,)\n",
    "        # reconstruction_loss = tf.reduce_mean(loss_per_example)\n",
    "        # reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.mse(data, reconstruction),axis=(1, 2)))\n",
    "\n",
    "        squared_error = tf.math.squared_difference(data, reconstruction)  # shape: (batch, 200, 3)\n",
    "        loss_per_example = tf.reduce_sum(squared_error, axis=[1, 2])       # shape: (batch,)\n",
    "        reconstruction_loss = tf.reduce_mean(loss_per_example) \n",
    "        \n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        total_loss = (reconstruction_loss + tf.reduce_mean(kl_loss)) / (max_len * 3.0)\n",
    "        \n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"total_loss\": total_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "260caa15-e577-4112-a7a6-0130eede6920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mask :  KerasTensor(type_spec=TensorSpec(shape=(None, 1024), dtype=tf.bool, name=None), name='masking/Squeeze:0')\n",
      "mask after first assert:  KerasTensor(type_spec=TensorSpec(shape=(None, 1024), dtype=tf.bool, name=None), name='Placeholder_4:0')\n",
      "input shape after conv2:  (None, 512, 256)\n",
      "pooled mask after conv2:  KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.bool, name=None), name='Placeholder_2:0')\n",
      "mask after 2nd conv Assert:  KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.bool, name=None), name='Placeholder_4:0')\n",
      "Model: \"Encoder_Condensation100_Kernel_size3_Filter128\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1024, 3)]            0         []                            \n",
      "                                                                                                  \n",
      " masking (Masking)           (None, 1024, 3)              0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " masked_zero (MaskedZero)    (None, 1024, 3)              0         ['masking[0][0]']             \n",
      "                                                                                                  \n",
      " assert_masked_zeros (Asser  (None, 1024, 3)              0         ['masking[0][0]',             \n",
      " tMaskedZeros)                                                       'masked_zero[0][0]']         \n",
      "                                                                                                  \n",
      " masked_conv1d (MaskedConv1  (None, 1024, 128)            1792      ['assert_masked_zeros[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " masked_zero_1 (MaskedZero)  (None, 1024, 128)            0         ['masked_conv1d[0][0]']       \n",
      "                                                                                                  \n",
      " assert_masked_zeros_1 (Ass  (None, 1024, 128)            0         ['masked_conv1d[0][0]',       \n",
      " ertMaskedZeros)                                                     'masked_zero_1[0][0]']       \n",
      "                                                                                                  \n",
      " masked_conv1d_1 (MaskedCon  (None, 512, 256)             99584     ['assert_masked_zeros_1[0][0]'\n",
      " v1D)                                                               ]                             \n",
      "                                                                                                  \n",
      " masked_zero_2 (MaskedZero)  (None, 512, 256)             0         ['masked_conv1d_1[0][0]']     \n",
      "                                                                                                  \n",
      " assert_masked_zeros_2 (Ass  (None, 512, 256)             0         ['masked_conv1d_1[0][0]',     \n",
      " ertMaskedZeros)                                                     'masked_zero_2[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 131072)               0         ['assert_masked_zeros_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 100)                  1310730   ['flatten[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 100)                  1310730   ['flatten[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " extract_mask (ExtractMask)  (None, 1024)                 0         ['masking[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26315976 (100.39 MB)\n",
      "Trainable params: 26315208 (100.38 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Mask at decoder output :  KerasTensor(type_spec=TensorSpec(shape=(None, 1024), dtype=tf.bool, name=None), name='Placeholder_2:0')\n",
      "Model: \"Decoder_Condensation_100_Kernel_size3_Filter128\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 25, 4)                0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_transpose (Conv1DTr  (None, 50, 256)              3328      ['reshape[0][0]']             \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 50, 256)              1024      ['conv1d_transpose[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 50, 256)              0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 12800)                0         ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 3072)                 3932467   ['flatten_1[0][0]']           \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1024, 3)              0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 1024)]               0         []                            \n",
      "                                                                                                  \n",
      " masked_zero_3 (MaskedZero)  (None, 1024, 3)              0         ['reshape_1[0][0]',           \n",
      "                                                                     'input_3[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 39329024 (150.03 MB)\n",
      "Trainable params: 39328512 (150.03 MB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder_Condensation100_Ke  [(None, 100),             26315976  \n",
      " rnel_size3_Filter128 (Func   (None, 100),                       \n",
      " tional)                      (None, 1024)]                      \n",
      "                                                                 \n",
      " Decoder_Condensation_100_K  (None, 1024, 3)           39329024  \n",
      " ernel_size3_Filter128 (Fun                                      \n",
      " ctional)                                                        \n",
      "                                                                 \n",
      " sampling (Sampling)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65645006 (250.42 MB)\n",
      "Trainable params: 65643720 (250.41 MB)\n",
      "Non-trainable params: 1286 (5.02 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 02:55:54.087449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2025-06-04 02:55:55.094157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-06-04 02:55:55.171530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x791f4eaf0fb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-04 02:55:55.171553: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2025-06-04 02:55:55.176246: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-04 02:55:55.293140: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23667/23667 [==============================] - 556s 23ms/step - total_loss: 0.0226 - reconstruction_loss: 67.9393 - kl_loss: 1.5508 - val_total_loss: 0.0174\n",
      "Epoch 2/200\n",
      "23667/23667 [==============================] - 546s 23ms/step - total_loss: 0.0210 - reconstruction_loss: 62.9553 - kl_loss: 1.6797 - val_total_loss: 0.0170\n",
      "Epoch 3/200\n",
      "23667/23667 [==============================] - 536s 23ms/step - total_loss: 0.0205 - reconstruction_loss: 61.1940 - kl_loss: 1.7446 - val_total_loss: 0.0166\n",
      "Epoch 4/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0202 - reconstruction_loss: 60.1552 - kl_loss: 1.7780 - val_total_loss: 0.0164\n",
      "Epoch 5/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0199 - reconstruction_loss: 59.4821 - kl_loss: 1.7982 - val_total_loss: 0.0164\n",
      "Epoch 6/200\n",
      "23667/23667 [==============================] - 550s 23ms/step - total_loss: 0.0198 - reconstruction_loss: 59.0384 - kl_loss: 1.8107 - val_total_loss: 0.0163\n",
      "Epoch 7/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0197 - reconstruction_loss: 58.7119 - kl_loss: 1.8205 - val_total_loss: 0.0162\n",
      "Epoch 8/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0196 - reconstruction_loss: 58.4599 - kl_loss: 1.8278 - val_total_loss: 0.0163\n",
      "Epoch 9/200\n",
      "23667/23667 [==============================] - 550s 23ms/step - total_loss: 0.0196 - reconstruction_loss: 58.2435 - kl_loss: 1.8352 - val_total_loss: 0.0161\n",
      "Epoch 10/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0195 - reconstruction_loss: 58.0433 - kl_loss: 1.8428 - val_total_loss: 0.0161\n",
      "Epoch 11/200\n",
      "23667/23667 [==============================] - 547s 23ms/step - total_loss: 0.0194 - reconstruction_loss: 57.8484 - kl_loss: 1.8514 - val_total_loss: 0.0161\n",
      "Epoch 12/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0194 - reconstruction_loss: 57.6903 - kl_loss: 1.8561 - val_total_loss: 0.0161\n",
      "Epoch 13/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0193 - reconstruction_loss: 57.5553 - kl_loss: 1.8614 - val_total_loss: 0.0161\n",
      "Epoch 14/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0193 - reconstruction_loss: 57.4414 - kl_loss: 1.8663 - val_total_loss: 0.0160\n",
      "Epoch 15/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0193 - reconstruction_loss: 57.3358 - kl_loss: 1.8696 - val_total_loss: 0.0160\n",
      "Epoch 16/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0192 - reconstruction_loss: 57.2338 - kl_loss: 1.8747 - val_total_loss: 0.0161\n",
      "Epoch 17/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0192 - reconstruction_loss: 57.1364 - kl_loss: 1.8791 - val_total_loss: 0.0160\n",
      "Epoch 18/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0192 - reconstruction_loss: 57.0470 - kl_loss: 1.8839 - val_total_loss: 0.0160\n",
      "Epoch 19/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0192 - reconstruction_loss: 56.9552 - kl_loss: 1.8883 - val_total_loss: 0.0160\n",
      "Epoch 20/200\n",
      "23667/23667 [==============================] - 550s 23ms/step - total_loss: 0.0191 - reconstruction_loss: 56.8765 - kl_loss: 1.8916 - val_total_loss: 0.0159\n",
      "Epoch 21/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0191 - reconstruction_loss: 56.7977 - kl_loss: 1.8955 - val_total_loss: 0.0159\n",
      "Epoch 22/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0191 - reconstruction_loss: 56.7307 - kl_loss: 1.9000 - val_total_loss: 0.0159\n",
      "Epoch 23/200\n",
      "23667/23667 [==============================] - 547s 23ms/step - total_loss: 0.0191 - reconstruction_loss: 56.6597 - kl_loss: 1.9036 - val_total_loss: 0.0158\n",
      "Epoch 24/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0190 - reconstruction_loss: 56.5928 - kl_loss: 1.9078 - val_total_loss: 0.0158\n",
      "Epoch 25/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0190 - reconstruction_loss: 56.5274 - kl_loss: 1.9116 - val_total_loss: 0.0158\n",
      "Epoch 26/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0190 - reconstruction_loss: 56.4686 - kl_loss: 1.9151 - val_total_loss: 0.0157\n",
      "Epoch 27/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0190 - reconstruction_loss: 56.4113 - kl_loss: 1.9185 - val_total_loss: 0.0158\n",
      "Epoch 28/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0190 - reconstruction_loss: 56.3504 - kl_loss: 1.9226 - val_total_loss: 0.0158\n",
      "Epoch 29/200\n",
      "23667/23667 [==============================] - 550s 23ms/step - total_loss: 0.0190 - reconstruction_loss: 56.2933 - kl_loss: 1.9259 - val_total_loss: 0.0157\n",
      "Epoch 30/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0189 - reconstruction_loss: 56.2346 - kl_loss: 1.9294 - val_total_loss: 0.0158\n",
      "Epoch 31/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0189 - reconstruction_loss: 56.1789 - kl_loss: 1.9320 - val_total_loss: 0.0158\n",
      "Epoch 32/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0189 - reconstruction_loss: 56.1335 - kl_loss: 1.9356 - val_total_loss: 0.0157\n",
      "Epoch 33/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0189 - reconstruction_loss: 56.0849 - kl_loss: 1.9380 - val_total_loss: 0.0157\n",
      "Epoch 34/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0189 - reconstruction_loss: 56.0417 - kl_loss: 1.9400 - val_total_loss: 0.0156\n",
      "Epoch 35/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0189 - reconstruction_loss: 56.0073 - kl_loss: 1.9430 - val_total_loss: 0.0157\n",
      "Epoch 36/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.9597 - kl_loss: 1.9453 - val_total_loss: 0.0156\n",
      "Epoch 37/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.9192 - kl_loss: 1.9485 - val_total_loss: 0.0157\n",
      "Epoch 38/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.8770 - kl_loss: 1.9511 - val_total_loss: 0.0155\n",
      "Epoch 39/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.8465 - kl_loss: 1.9542 - val_total_loss: 0.0156\n",
      "Epoch 40/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.8031 - kl_loss: 1.9565 - val_total_loss: 0.0156\n",
      "Epoch 41/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.7617 - kl_loss: 1.9589 - val_total_loss: 0.0155\n",
      "Epoch 42/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.7285 - kl_loss: 1.9619 - val_total_loss: 0.0156\n",
      "Epoch 43/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.6886 - kl_loss: 1.9649 - val_total_loss: 0.0156\n",
      "Epoch 44/200\n",
      "23667/23667 [==============================] - 547s 23ms/step - total_loss: 0.0188 - reconstruction_loss: 55.6614 - kl_loss: 1.9675 - val_total_loss: 0.0155\n",
      "Epoch 45/200\n",
      "23667/23667 [==============================] - 547s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.6294 - kl_loss: 1.9706 - val_total_loss: 0.0155\n",
      "Epoch 46/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.5946 - kl_loss: 1.9727 - val_total_loss: 0.0155\n",
      "Epoch 47/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.5653 - kl_loss: 1.9758 - val_total_loss: 0.0155\n",
      "Epoch 48/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.5311 - kl_loss: 1.9782 - val_total_loss: 0.0155\n",
      "Epoch 49/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.4987 - kl_loss: 1.9806 - val_total_loss: 0.0154\n",
      "Epoch 50/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.4622 - kl_loss: 1.9831 - val_total_loss: 0.0155\n",
      "Epoch 51/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.4370 - kl_loss: 1.9869 - val_total_loss: 0.0155\n",
      "Epoch 52/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.4007 - kl_loss: 1.9897 - val_total_loss: 0.0154\n",
      "Epoch 53/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.3610 - kl_loss: 1.9919 - val_total_loss: 0.0154\n",
      "Epoch 54/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.3386 - kl_loss: 1.9949 - val_total_loss: 0.0154\n",
      "Epoch 55/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0187 - reconstruction_loss: 55.3053 - kl_loss: 1.9972 - val_total_loss: 0.0154\n",
      "Epoch 56/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.2775 - kl_loss: 2.0003 - val_total_loss: 0.0153\n",
      "Epoch 57/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.2448 - kl_loss: 2.0022 - val_total_loss: 0.0154\n",
      "Epoch 58/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.2161 - kl_loss: 2.0042 - val_total_loss: 0.0154\n",
      "Epoch 59/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.2002 - kl_loss: 2.0064 - val_total_loss: 0.0154\n",
      "Epoch 60/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.1640 - kl_loss: 2.0082 - val_total_loss: 0.0155\n",
      "Epoch 61/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.1439 - kl_loss: 2.0104 - val_total_loss: 0.0153\n",
      "Epoch 62/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.1191 - kl_loss: 2.0123 - val_total_loss: 0.0154\n",
      "Epoch 63/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.0930 - kl_loss: 2.0142 - val_total_loss: 0.0154\n",
      "Epoch 64/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.0682 - kl_loss: 2.0159 - val_total_loss: 0.0154\n",
      "Epoch 65/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.0429 - kl_loss: 2.0176 - val_total_loss: 0.0154\n",
      "Epoch 66/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.0220 - kl_loss: 2.0194 - val_total_loss: 0.0153\n",
      "Epoch 67/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 55.0019 - kl_loss: 2.0213 - val_total_loss: 0.0153\n",
      "Epoch 68/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0186 - reconstruction_loss: 54.9794 - kl_loss: 2.0227 - val_total_loss: 0.0153\n",
      "Epoch 69/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.9582 - kl_loss: 2.0248 - val_total_loss: 0.0153\n",
      "Epoch 70/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.9369 - kl_loss: 2.0269 - val_total_loss: 0.0154\n",
      "Epoch 71/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.9178 - kl_loss: 2.0290 - val_total_loss: 0.0154\n",
      "Epoch 72/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.8853 - kl_loss: 2.0303 - val_total_loss: 0.0153\n",
      "Epoch 73/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.8709 - kl_loss: 2.0324 - val_total_loss: 0.0153\n",
      "Epoch 74/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.8412 - kl_loss: 2.0346 - val_total_loss: 0.0153\n",
      "Epoch 75/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.8215 - kl_loss: 2.0368 - val_total_loss: 0.0153\n",
      "Epoch 76/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.8027 - kl_loss: 2.0385 - val_total_loss: 0.0154\n",
      "Epoch 77/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.7777 - kl_loss: 2.0395 - val_total_loss: 0.0152\n",
      "Epoch 78/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.7586 - kl_loss: 2.0412 - val_total_loss: 0.0155\n",
      "Epoch 79/200\n",
      "23667/23667 [==============================] - 550s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.7331 - kl_loss: 2.0442 - val_total_loss: 0.0153\n",
      "Epoch 80/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.7242 - kl_loss: 2.0452 - val_total_loss: 0.0153\n",
      "Epoch 81/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.6981 - kl_loss: 2.0468 - val_total_loss: 0.0153\n",
      "Epoch 82/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.6856 - kl_loss: 2.0470 - val_total_loss: 0.0153\n",
      "Epoch 83/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.6661 - kl_loss: 2.0487 - val_total_loss: 0.0153\n",
      "Epoch 84/200\n",
      "23667/23667 [==============================] - 548s 23ms/step - total_loss: 0.0185 - reconstruction_loss: 54.6505 - kl_loss: 2.0495 - val_total_loss: 0.0153\n",
      "Epoch 85/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0184 - reconstruction_loss: 54.6265 - kl_loss: 2.0507 - val_total_loss: 0.0153\n",
      "Epoch 86/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0184 - reconstruction_loss: 54.6200 - kl_loss: 2.0523 - val_total_loss: 0.0153\n",
      "Epoch 87/200\n",
      "23667/23667 [==============================] - 549s 23ms/step - total_loss: 0.0184 - reconstruction_loss: 54.5993 - kl_loss: 2.0529 - val_total_loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:11:22.110702: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.48GiB (rounded to 2658902016)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-06-04 16:11:22.110766: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2025-06-04 16:11:22.110795: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 92, Chunks in use: 91. 23.0KiB allocated for chunks. 22.8KiB in use in bin. 2.2KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110814: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 24, Chunks in use: 23. 12.0KiB allocated for chunks. 11.5KiB in use in bin. 10.7KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110830: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 29, Chunks in use: 29. 31.0KiB allocated for chunks. 31.0KiB in use in bin. 29.1KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110846: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110863: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 3, Chunks in use: 3. 13.5KiB allocated for chunks. 13.5KiB in use in bin. 13.5KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110878: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 6, Chunks in use: 6. 72.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110894: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 2, Chunks in use: 1. 52.8KiB allocated for chunks. 28.0KiB in use in bin. 24.0KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110909: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 43.8KiB allocated for chunks. 43.8KiB in use in bin. 28.0KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110925: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 3, Chunks in use: 2. 297.0KiB allocated for chunks. 208.0KiB in use in bin. 208.0KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110938: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110953: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 5, Chunks in use: 4. 1.96MiB allocated for chunks. 1.58MiB in use in bin. 1.56MiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110969: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 712.5KiB allocated for chunks. 712.5KiB in use in bin. 384.0KiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110983: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.75MiB allocated for chunks. 1.75MiB in use in bin. 1.75MiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.110996: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111008: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111021: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111034: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111050: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 6, Chunks in use: 5. 300.00MiB allocated for chunks. 250.00MiB in use in bin. 250.00MiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111066: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 99.62MiB allocated for chunks. 99.62MiB in use in bin. 50.00MiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111082: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 3. 699.43MiB allocated for chunks. 450.00MiB in use in bin. 450.00MiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111106: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 2. 12.21GiB allocated for chunks. 11.14GiB in use in bin. 11.14GiB client-requested in use in bin.\n",
      "2025-06-04 16:11:22.111124: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 2.48GiB was 256.00MiB, Chunk State: \n",
      "2025-06-04 16:11:22.111145: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 1.06GiB | Requested Size: 1.0KiB | in_use: 0 | bin_num: 20, prev:   Size: 150.00MiB | Requested Size: 150.00MiB | in_use: 1 | bin_num: -1\n",
      "2025-06-04 16:11:22.111156: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 14266597376\n",
      "2025-06-04 16:11:22.111173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000000 of size 1280 next 1\n",
      "2025-06-04 16:11:22.111205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000500 of size 256 next 2\n",
      "2025-06-04 16:11:22.111217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000600 of size 256 next 3\n",
      "2025-06-04 16:11:22.111228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000700 of size 256 next 5\n",
      "2025-06-04 16:11:22.111238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000800 of size 256 next 6\n",
      "2025-06-04 16:11:22.111248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000900 of size 256 next 10\n",
      "2025-06-04 16:11:22.111258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000a00 of size 256 next 4\n",
      "2025-06-04 16:11:22.111269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000b00 of size 256 next 7\n",
      "2025-06-04 16:11:22.111279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000c00 of size 256 next 13\n",
      "2025-06-04 16:11:22.111290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000d00 of size 256 next 8\n",
      "2025-06-04 16:11:22.111300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000e00 of size 256 next 58\n",
      "2025-06-04 16:11:22.111310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c000f00 of size 256 next 9\n",
      "2025-06-04 16:11:22.111321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001000 of size 256 next 15\n",
      "2025-06-04 16:11:22.111331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001100 of size 256 next 14\n",
      "2025-06-04 16:11:22.111341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001200 of size 256 next 25\n",
      "2025-06-04 16:11:22.111351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001300 of size 256 next 19\n",
      "2025-06-04 16:11:22.111362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001400 of size 256 next 20\n",
      "2025-06-04 16:11:22.111373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001500 of size 256 next 21\n",
      "2025-06-04 16:11:22.111383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001600 of size 256 next 24\n",
      "2025-06-04 16:11:22.111393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001700 of size 256 next 22\n",
      "2025-06-04 16:11:22.111404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001800 of size 256 next 23\n",
      "2025-06-04 16:11:22.111414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001900 of size 256 next 11\n",
      "2025-06-04 16:11:22.111425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001a00 of size 256 next 27\n",
      "2025-06-04 16:11:22.111436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001b00 of size 512 next 28\n",
      "2025-06-04 16:11:22.111447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c001d00 of size 1280 next 30\n",
      "2025-06-04 16:11:22.111458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002200 of size 256 next 31\n",
      "2025-06-04 16:11:22.111468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002300 of size 256 next 32\n",
      "2025-06-04 16:11:22.111480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002400 of size 512 next 35\n",
      "2025-06-04 16:11:22.111491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002600 of size 256 next 33\n",
      "2025-06-04 16:11:22.111501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002700 of size 256 next 34\n",
      "2025-06-04 16:11:22.111511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002800 of size 512 next 39\n",
      "2025-06-04 16:11:22.111521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002a00 of size 512 next 37\n",
      "2025-06-04 16:11:22.111532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002c00 of size 512 next 38\n",
      "2025-06-04 16:11:22.111542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002e00 of size 256 next 53\n",
      "2025-06-04 16:11:22.111552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c002f00 of size 256 next 42\n",
      "2025-06-04 16:11:22.111562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c003000 of size 256 next 43\n",
      "2025-06-04 16:11:22.111573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c003100 of size 256 next 44\n",
      "2025-06-04 16:11:22.111584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c003200 of size 1024 next 47\n",
      "2025-06-04 16:11:22.111594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c003600 of size 256 next 45\n",
      "2025-06-04 16:11:22.111605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c003700 of size 256 next 46\n",
      "2025-06-04 16:11:22.111615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c003800 of size 1024 next 51\n",
      "2025-06-04 16:11:22.111626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c003c00 of size 1024 next 49\n",
      "2025-06-04 16:11:22.111636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c004000 of size 1024 next 50\n",
      "2025-06-04 16:11:22.111646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c004400 of size 512 next 12\n",
      "2025-06-04 16:11:22.111657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c004600 of size 512 next 54\n",
      "2025-06-04 16:11:22.111667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c004800 of size 256 next 55\n",
      "2025-06-04 16:11:22.111677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c004900 of size 512 next 56\n",
      "2025-06-04 16:11:22.111688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c004b00 of size 1280 next 57\n",
      "2025-06-04 16:11:22.111699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c005000 of size 44800 next 17\n",
      "2025-06-04 16:11:22.111710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c00ff00 of size 28672 next 16\n",
      "2025-06-04 16:11:22.111721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c016f00 of size 114688 next 18\n",
      "2025-06-04 16:11:22.111732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c032f00 of size 98304 next 26\n",
      "2025-06-04 16:11:22.111745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c04af00 of size 458752 next 36\n",
      "2025-06-04 16:11:22.111758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c0baf00 of size 393216 next 41\n",
      "2025-06-04 16:11:22.111770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c11af00 of size 1835008 next 40\n",
      "2025-06-04 16:11:22.111782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2daf00 of size 512 next 52\n",
      "2025-06-04 16:11:22.111794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2db100 of size 512 next 48\n",
      "2025-06-04 16:11:22.111807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2db300 of size 1536 next 63\n",
      "2025-06-04 16:11:22.111819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2db900 of size 1024 next 61\n",
      "2025-06-04 16:11:22.111831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dbd00 of size 1024 next 62\n",
      "2025-06-04 16:11:22.111845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dc100 of size 1024 next 66\n",
      "2025-06-04 16:11:22.111856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dc500 of size 512 next 184\n",
      "2025-06-04 16:11:22.111866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dc700 of size 512 next 67\n",
      "2025-06-04 16:11:22.111877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dc900 of size 256 next 68\n",
      "2025-06-04 16:11:22.111887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dca00 of size 256 next 69\n",
      "2025-06-04 16:11:22.111898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dcb00 of size 1024 next 75\n",
      "2025-06-04 16:11:22.111908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dcf00 of size 256 next 70\n",
      "2025-06-04 16:11:22.111919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dd000 of size 256 next 71\n",
      "2025-06-04 16:11:22.111929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dd100 of size 256 next 84\n",
      "2025-06-04 16:11:22.111939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dd200 of size 256 next 59\n",
      "2025-06-04 16:11:22.111949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dd300 of size 1024 next 29\n",
      "2025-06-04 16:11:22.111960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2dd700 of size 1024 next 78\n",
      "2025-06-04 16:11:22.111970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2ddb00 of size 1024 next 77\n",
      "2025-06-04 16:11:22.111980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2ddf00 of size 1024 next 79\n",
      "2025-06-04 16:11:22.111990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 79210c2de300 of size 25344 next 80\n",
      "2025-06-04 16:11:22.112002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e4600 of size 12288 next 81\n",
      "2025-06-04 16:11:22.112013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7600 of size 256 next 87\n",
      "2025-06-04 16:11:22.112023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 79210c2e7700 of size 256 next 85\n",
      "2025-06-04 16:11:22.112033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7800 of size 256 next 86\n",
      "2025-06-04 16:11:22.112044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7900 of size 256 next 90\n",
      "2025-06-04 16:11:22.112054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7a00 of size 256 next 91\n",
      "2025-06-04 16:11:22.112065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7b00 of size 256 next 92\n",
      "2025-06-04 16:11:22.112075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7c00 of size 256 next 93\n",
      "2025-06-04 16:11:22.112085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7d00 of size 256 next 94\n",
      "2025-06-04 16:11:22.112096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7e00 of size 256 next 95\n",
      "2025-06-04 16:11:22.112106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e7f00 of size 256 next 96\n",
      "2025-06-04 16:11:22.112116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8000 of size 256 next 98\n",
      "2025-06-04 16:11:22.112127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8100 of size 256 next 99\n",
      "2025-06-04 16:11:22.112137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8200 of size 256 next 100\n",
      "2025-06-04 16:11:22.112147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8300 of size 512 next 101\n",
      "2025-06-04 16:11:22.112158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8500 of size 512 next 102\n",
      "2025-06-04 16:11:22.112168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8700 of size 512 next 103\n",
      "2025-06-04 16:11:22.112179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8900 of size 512 next 104\n",
      "2025-06-04 16:11:22.112199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e8b00 of size 4608 next 105\n",
      "2025-06-04 16:11:22.112210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2e9d00 of size 4608 next 106\n",
      "2025-06-04 16:11:22.112220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2eaf00 of size 512 next 107\n",
      "2025-06-04 16:11:22.112231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2eb100 of size 512 next 108\n",
      "2025-06-04 16:11:22.112241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2eb300 of size 1024 next 109\n",
      "2025-06-04 16:11:22.112252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2eb700 of size 1024 next 110\n",
      "2025-06-04 16:11:22.112262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2ebb00 of size 1024 next 111\n",
      "2025-06-04 16:11:22.112272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2ebf00 of size 1024 next 112\n",
      "2025-06-04 16:11:22.112283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c2ec300 of size 729600 next 65\n",
      "2025-06-04 16:11:22.112295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 79210c39e500 of size 393216 next 64\n",
      "2025-06-04 16:11:22.112306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c3fe500 of size 393216 next 113\n",
      "2025-06-04 16:11:22.112316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c45e500 of size 1024 next 114\n",
      "2025-06-04 16:11:22.112326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c45e900 of size 1024 next 115\n",
      "2025-06-04 16:11:22.112337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79210c45ed00 of size 104462336 next 74\n",
      "2025-06-04 16:11:22.112349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7921127fe500 of size 52428800 next 73\n",
      "2025-06-04 16:11:22.112360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7921159fe500 of size 52428800 next 76\n",
      "2025-06-04 16:11:22.112371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792118bfe500 of size 52428800 next 116\n",
      "2025-06-04 16:11:22.112382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79211bdfe500 of size 512 next 117\n",
      "2025-06-04 16:11:22.112392: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79211bdfe700 of size 512 next 118\n",
      "2025-06-04 16:11:22.112403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79211bdfe900 of size 52428800 next 119\n",
      "2025-06-04 16:11:22.112413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79211effe900 of size 52428800 next 120\n",
      "2025-06-04 16:11:22.112424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7921221fe900 of size 512 next 121\n",
      "2025-06-04 16:11:22.112434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7921221feb00 of size 512 next 122\n",
      "2025-06-04 16:11:22.112445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7921221fed00 of size 12288 next 123\n",
      "2025-06-04 16:11:22.112455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122201d00 of size 12288 next 124\n",
      "2025-06-04 16:11:22.112466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122204d00 of size 1024 next 125\n",
      "2025-06-04 16:11:22.112477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122205100 of size 1024 next 126\n",
      "2025-06-04 16:11:22.112487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122205500 of size 1024 next 127\n",
      "2025-06-04 16:11:22.112497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122205900 of size 1024 next 128\n",
      "2025-06-04 16:11:22.112507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122205d00 of size 1024 next 129\n",
      "2025-06-04 16:11:22.112518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122206100 of size 1024 next 130\n",
      "2025-06-04 16:11:22.112528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122206500 of size 12288 next 133\n",
      "2025-06-04 16:11:22.112538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122209500 of size 12288 next 134\n",
      "2025-06-04 16:11:22.112550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220c500 of size 256 next 135\n",
      "2025-06-04 16:11:22.112561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220c600 of size 256 next 136\n",
      "2025-06-04 16:11:22.112572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220c700 of size 256 next 137\n",
      "2025-06-04 16:11:22.112582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220c800 of size 256 next 138\n",
      "2025-06-04 16:11:22.112592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220c900 of size 256 next 139\n",
      "2025-06-04 16:11:22.112603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220ca00 of size 256 next 140\n",
      "2025-06-04 16:11:22.112613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220cb00 of size 256 next 141\n",
      "2025-06-04 16:11:22.112624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220cc00 of size 256 next 142\n",
      "2025-06-04 16:11:22.112634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220cd00 of size 256 next 143\n",
      "2025-06-04 16:11:22.112644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220ce00 of size 256 next 144\n",
      "2025-06-04 16:11:22.112655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220cf00 of size 256 next 145\n",
      "2025-06-04 16:11:22.112665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d000 of size 256 next 146\n",
      "2025-06-04 16:11:22.112676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d100 of size 256 next 147\n",
      "2025-06-04 16:11:22.112686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d200 of size 256 next 148\n",
      "2025-06-04 16:11:22.112697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d300 of size 256 next 149\n",
      "2025-06-04 16:11:22.112707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d400 of size 256 next 150\n",
      "2025-06-04 16:11:22.112717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d500 of size 256 next 151\n",
      "2025-06-04 16:11:22.112727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d600 of size 256 next 152\n",
      "2025-06-04 16:11:22.112738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d700 of size 256 next 153\n",
      "2025-06-04 16:11:22.112748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d800 of size 256 next 165\n",
      "2025-06-04 16:11:22.112758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220d900 of size 256 next 200\n",
      "2025-06-04 16:11:22.112768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220da00 of size 256 next 154\n",
      "2025-06-04 16:11:22.112779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220db00 of size 256 next 162\n",
      "2025-06-04 16:11:22.112789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220dc00 of size 256 next 172\n",
      "2025-06-04 16:11:22.112800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220dd00 of size 256 next 181\n",
      "2025-06-04 16:11:22.112810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220de00 of size 256 next 183\n",
      "2025-06-04 16:11:22.112821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220df00 of size 256 next 204\n",
      "2025-06-04 16:11:22.112831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220e000 of size 256 next 189\n",
      "2025-06-04 16:11:22.112841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220e100 of size 256 next 227\n",
      "2025-06-04 16:11:22.112851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220e200 of size 256 next 205\n",
      "2025-06-04 16:11:22.112862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220e300 of size 512 next 168\n",
      "2025-06-04 16:11:22.112872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220e500 of size 256 next 226\n",
      "2025-06-04 16:11:22.112883: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220e600 of size 1792 next 160\n",
      "2025-06-04 16:11:22.112896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220ed00 of size 256 next 182\n",
      "2025-06-04 16:11:22.112907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220ee00 of size 256 next 194\n",
      "2025-06-04 16:11:22.112917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220ef00 of size 256 next 215\n",
      "2025-06-04 16:11:22.112927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220f000 of size 256 next 176\n",
      "2025-06-04 16:11:22.112938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220f100 of size 256 next 171\n",
      "2025-06-04 16:11:22.112948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220f200 of size 256 next 179\n",
      "2025-06-04 16:11:22.112959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220f300 of size 256 next 170\n",
      "2025-06-04 16:11:22.112969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220f400 of size 256 next 190\n",
      "2025-06-04 16:11:22.112979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220f500 of size 256 next 187\n",
      "2025-06-04 16:11:22.112990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212220f600 of size 416000 next 202\n",
      "2025-06-04 16:11:22.113001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 792122274f00 of size 512 next 225\n",
      "2025-06-04 16:11:22.113011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122275100 of size 4608 next 206\n",
      "2025-06-04 16:11:22.113022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792122276300 of size 12288 next 72\n",
      "2025-06-04 16:11:22.113032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 792122279300 of size 91136 next 157\n",
      "2025-06-04 16:11:22.113043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79212228f700 of size 52428800 next 60\n",
      "2025-06-04 16:11:22.113054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 79212548f700 of size 261549568 next 88\n",
      "2025-06-04 16:11:22.113065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792134dfe500 of size 9306169344 next 97\n",
      "2025-06-04 16:11:22.113076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79235f90c500 of size 157286400 next 131\n",
      "2025-06-04 16:11:22.113088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792368f0c500 of size 157286400 next 132\n",
      "2025-06-04 16:11:22.113099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 79237250c500 of size 2658902016 next 196\n",
      "2025-06-04 16:11:22.113110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 792410cc6500 of size 157286400 next 82\n",
      "2025-06-04 16:11:22.113121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 79241a2c6500 of size 1143905024 next 18446744073709551615\n",
      "2025-06-04 16:11:22.113131: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2025-06-04 16:11:22.113147: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 91 Chunks of size 256 totalling 22.8KiB\n",
      "2025-06-04 16:11:22.113160: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 23 Chunks of size 512 totalling 11.5KiB\n",
      "2025-06-04 16:11:22.113172: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 24 Chunks of size 1024 totalling 24.0KiB\n",
      "2025-06-04 16:11:22.113191: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 1280 totalling 3.8KiB\n",
      "2025-06-04 16:11:22.113203: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1536 totalling 1.5KiB\n",
      "2025-06-04 16:11:22.113215: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2025-06-04 16:11:22.113228: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 4608 totalling 13.5KiB\n",
      "2025-06-04 16:11:22.113240: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 12288 totalling 72.0KiB\n",
      "2025-06-04 16:11:22.113251: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 28672 totalling 28.0KiB\n",
      "2025-06-04 16:11:22.113263: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 44800 totalling 43.8KiB\n",
      "2025-06-04 16:11:22.113277: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 98304 totalling 96.0KiB\n",
      "2025-06-04 16:11:22.113290: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 114688 totalling 112.0KiB\n",
      "2025-06-04 16:11:22.113302: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 393216 totalling 768.0KiB\n",
      "2025-06-04 16:11:22.113314: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 416000 totalling 406.2KiB\n",
      "2025-06-04 16:11:22.113326: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 458752 totalling 448.0KiB\n",
      "2025-06-04 16:11:22.113338: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 729600 totalling 712.5KiB\n",
      "2025-06-04 16:11:22.113350: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1835008 totalling 1.75MiB\n",
      "2025-06-04 16:11:22.113362: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 52428800 totalling 250.00MiB\n",
      "2025-06-04 16:11:22.113375: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 104462336 totalling 99.62MiB\n",
      "2025-06-04 16:11:22.113387: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 157286400 totalling 450.00MiB\n",
      "2025-06-04 16:11:22.113398: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2658902016 totalling 2.48GiB\n",
      "2025-06-04 16:11:22.113410: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 9306169344 totalling 8.67GiB\n",
      "2025-06-04 16:11:22.113423: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 11.93GiB\n",
      "2025-06-04 16:11:22.113434: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 14266597376 memory_limit_: 14266597376 available bytes: 0 curr_region_allocation_bytes_: 28533194752\n",
      "2025-06-04 16:11:22.113454: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     14266597376\n",
      "InUse:                     12808203520\n",
      "MaxInUse:                  13166008064\n",
      "NumAllocs:                   427104199\n",
      "MaxAllocSize:               9306169344\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-06-04 16:11:22.113493: W tensorflow/tsl/framework/bfc_allocator.cc:497] ***_****************************************************************************************________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 84\u001b[0m\n\u001b[1;32m     76\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     77\u001b[0m monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_total_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,       \n\u001b[1;32m     78\u001b[0m patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,               \n\u001b[1;32m     79\u001b[0m restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m variational_ae\u001b[38;5;241m.\u001b[39mfit(train_fmatrix_embed, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m[val_fmatrix_embed],callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m eval_value \u001b[38;5;241m=\u001b[39m \u001b[43mvariational_ae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_fmatrix_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, return_dict=True\u001b[39;00m\n\u001b[1;32m     85\u001b[0m val_loss_value \u001b[38;5;241m=\u001b[39m eval_value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Identity\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#####\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu3/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "units = [4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96]\n",
    "filter_num = [128]\n",
    "filter_size = [3]\n",
    "for codings_size in units:\n",
    "    for size in filter_size:\n",
    "        for filte_r in filter_num:\n",
    "            tf.keras.backend.clear_session() \n",
    "            flag = 1\n",
    "            \n",
    "            inputs = tf.keras.layers.Input(shape=[max_len, 3])\n",
    "            masked_inputs = layers.Masking(mask_value=0.0)(inputs)   \n",
    "            print(\"Original mask : \",masked_inputs._keras_mask)\n",
    "            \n",
    "            # #Extract the mask only from the masking layer\n",
    "            mask = ExtractMask()(masked_inputs) \n",
    "            \n",
    "            masked_zero_inputs = MaskedZero()(masked_inputs)\n",
    "            assert_zero_0  = AssertMaskedZeros()([masked_inputs,masked_zero_inputs])\n",
    "            print(\"mask after first assert: \",assert_zero_0._keras_mask)\n",
    "            \n",
    "            Z = MaskedConv1D(filter_num=filte_r, filter_size=size, strides = 1,pool_size=None)(assert_zero_0)\n",
    "            \n",
    "            masked_Z_conv1 = MaskedZero()(Z)\n",
    "            assert_zero_1  = AssertMaskedZeros()([Z,masked_Z_conv1])\n",
    "            \n",
    "            Z = MaskedConv1D(filter_num=filte_r*2, filter_size=size,strides = 2,pool_size=2)(assert_zero_1)\n",
    "            print(\"input shape after conv2: \",Z.shape)\n",
    "            # pooled_mask = downsample_mask(mask, 2)\n",
    "                        \n",
    "            masked_Z_conv2 = MaskedZero()(Z)#, pooled_mask)\n",
    "            print(\"pooled mask after conv2: \",masked_Z_conv2._keras_mask)\n",
    "            assert_zero_2  = AssertMaskedZeros()([Z,masked_Z_conv2])\n",
    "            print(\"mask after 2nd conv Assert: \",assert_zero_2._keras_mask)\n",
    "        \n",
    "            Z = tf.keras.layers.Flatten()(assert_zero_2)\n",
    "            \n",
    "            codings_mean    = tf.keras.layers.Dense(codings_size*25)(Z)  # μ\n",
    "            codings_log_var = tf.keras.layers.Dense(codings_size*25)(Z)  # γ\n",
    "            if flag==1:\n",
    "                variational_encoder = tf.keras.Model(\n",
    "                    inputs=[inputs], outputs=[codings_mean, codings_log_var, mask],\n",
    "                    name = f\"Encoder_Condensation{codings_size*25}_Kernel_size{size}_Filter{filte_r}\")\n",
    "                variational_encoder.summary()\n",
    "\n",
    "            flag = 0\n",
    "            decoder_inputs = tf.keras.layers.Input(shape=[codings_size*25])\n",
    "            decoder_mask   = tf.keras.layers.Input(shape=[max_len], dtype='bool')\n",
    "            x = tf.keras.layers.Reshape([25,codings_size])(decoder_inputs)\n",
    "            x = tf.keras.layers.Conv1DTranspose(filte_r*2, kernel_size=size, padding=\"same\",strides=2)(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)    \n",
    "            x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "            x = tf.keras.layers.Flatten()(x)\n",
    "            x = tf.keras.layers.Dense(max_len*3)(x)\n",
    "            x = tf.keras.layers.Reshape([max_len,3])(x)\n",
    "            \n",
    "            outputs = MaskedZero()(x, decoder_mask)\n",
    "            print(\"Mask at decoder output : \",outputs._keras_mask)\n",
    "            assert_zero_3  = AssertMaskedZeros()([x,outputs])\n",
    "                        \n",
    "            if flag == 0:\n",
    "                variational_decoder = tf.keras.Model(inputs=[decoder_inputs,decoder_mask], outputs=[outputs],\n",
    "                name = f\"Decoder_Condensation_{codings_size*25}_Kernel_size{size}_Filter{filte_r}\")\n",
    "                variational_decoder.summary()\n",
    "\n",
    "            #####\n",
    "            #Model Summary\n",
    "            #####\n",
    "            variational_ae = VAE(variational_encoder, variational_decoder)\n",
    "            variational_ae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3))#,loss=lambda y_true, y_pred: 0.0) #placeholder for loss\n",
    "            variational_ae(inputs)\n",
    "            variational_ae.summary()\n",
    "\n",
    "            #####\n",
    "            #Training and Evaluation\n",
    "            #####\n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_total_loss',       \n",
    "            patience=10,               \n",
    "            restore_best_weights=True,\n",
    "            mode = 'min')\n",
    "            \n",
    "            variational_ae.fit(train_fmatrix_embed, epochs=200, validation_data=[val_fmatrix_embed],callbacks=[early_stopping], verbose=1)\n",
    "            with tf.device('/CPU:0'):\n",
    "                eval_value = variational_ae.evaluate(val_fmatrix_embed, return_dict=True) #, return_dict=True\n",
    "            val_loss_value = eval_value[\"total_loss\"]\n",
    "\n",
    "            #####\n",
    "            # Identity\n",
    "            #####\n",
    "            identity_scores_list = []\n",
    "            num_repeats = 5\n",
    "            for i in range(val1000_fmatrix_embed.shape[0]):\n",
    "                orig = val1000_fmatrix_embed[i] #1024,3\n",
    "                # Determine original (true) sequence length\n",
    "                orig_len = remove_masking(orig[np.newaxis, ...])\n",
    "                orig_trimmed = orig[:orig_len, :]\n",
    " \n",
    "                # Convert to letter sequence\n",
    "                orig_letters = back_to_letters(\n",
    "                    np.squeeze(orig_trimmed),\n",
    "                    type_of_seq='Original'\n",
    "                )\n",
    "                # Run model 5 times on the same input\n",
    "                all_preds = [variational_ae.predict(orig[np.newaxis, ...], verbose=0)[0] for _ in range(num_repeats)]\n",
    "                # print(all_preds[0],all_preds[0].shape)\n",
    "            \n",
    "                # Compute identity scores\n",
    "                scores_i = []\n",
    "                for pred in all_preds:\n",
    "                    pred_len = remove_masking(pred[np.newaxis, ...])\n",
    "                    pred_trimmed = pred[:pred_len, :]\n",
    "            \n",
    "                    pred_letters = back_to_letters(\n",
    "                        np.squeeze(pred_trimmed),\n",
    "                        type_of_seq='Predicted'\n",
    "                    )\n",
    "                    score = run_needle(pred_letters, orig_letters)\n",
    "                    scores_i.append(score)\n",
    "                mean_score = np.mean(scores_i)\n",
    "                identity_scores_list.append(mean_score)\n",
    "            identity_scores_str = ', '.join(map(str, identity_scores_list))\n",
    "            # once all batches done:\n",
    "            mean_identity = np.mean(identity_scores_list)\n",
    "            std_deviation = np.std(identity_scores_list)\n",
    "            model_name  = f\"GPConvVAE{max_len}_Condensed{25*codings_size}_{filter_num[0]}_k{filter_size[0]}\"\n",
    "            result_line = f\"{model_name}|{val_loss_value}|{identity_scores_str}|{mean_identity}|{std_deviation}\"\n",
    "            with open(f\"{save_csv}/SirDataConvVAEModelsCondensation_{max_len}.csv\",'a') as f:   \n",
    "                f.write(result_line + \"\\n\")\n",
    "            \n",
    "            model_filename = f\"{saved_model_path}/VAE_models/{model_name}.h5\"\n",
    "            variational_ae.save_weights(model_filename)\n",
    "            \n",
    "            # Cleanup\n",
    "            del variational_encoder\n",
    "            del variational_decoder\n",
    "            del variational_ae\n",
    "            tf.keras.backend.clear_session()\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "653e8371-ee23-477e-bed1-b2a056492b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'variational_ae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     eval_value \u001b[38;5;241m=\u001b[39m \u001b[43mvariational_ae\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(val_fmatrix_embed, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'variational_ae' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    eval_value = variational_ae.evaluate(val_fmatrix_embed, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5823104e-8937-4ac1-a16d-610fe0a845a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_value = variational_ae.evaluate(val_fmatrix_embed, return_dict=True) #, return_dict=True\n",
    "val_loss_value = eval_value[\"total_loss\"]\n",
    "#####\n",
    "# Identity\n",
    "#####\n",
    "identity_scores_list = []\n",
    "num_repeats = 5\n",
    "for i in range(val1000_fmatrix_embed.shape[0]):\n",
    "    orig = val1000_fmatrix_embed[i] #1024,3\n",
    "    # Determine original (true) sequence length\n",
    "    orig_len = remove_masking(orig[np.newaxis, ...])\n",
    "    orig_trimmed = orig[:orig_len, :]\n",
    "\n",
    "    # Convert to letter sequence\n",
    "    orig_letters = back_to_letters(\n",
    "        np.squeeze(orig_trimmed),\n",
    "        type_of_seq='Original'\n",
    "    )\n",
    "    # Run model 5 times on the same input\n",
    "    all_preds = [variational_ae.predict(orig[np.newaxis, ...], verbose=0)[0] for _ in range(num_repeats)]\n",
    "    # print(all_preds[0],all_preds[0].shape)\n",
    "\n",
    "    # Compute identity scores\n",
    "    scores_i = []\n",
    "    for pred in all_preds:\n",
    "        pred_len = remove_masking(pred[np.newaxis, ...])\n",
    "        pred_trimmed = pred[:pred_len, :]\n",
    "\n",
    "        pred_letters = back_to_letters(\n",
    "            np.squeeze(pred_trimmed),\n",
    "            type_of_seq='Predicted'\n",
    "        )\n",
    "        score = run_needle(pred_letters, orig_letters)\n",
    "        scores_i.append(score)\n",
    "    mean_score = np.mean(scores_i)\n",
    "    identity_scores_list.append(mean_score)\n",
    "identity_scores_str = ', '.join(map(str, identity_scores_list))\n",
    "# once all batches done:\n",
    "mean_identity = np.mean(identity_scores_list)\n",
    "std_deviation = np.std(identity_scores_list)\n",
    "model_name  = f\"GPConvVAE{max_len}_Condensed{25*codings_size}_{filter_num[0]}_k{filter_size[0]}\"\n",
    "result_line = f\"{model_name}|{val_loss_value}|{identity_scores_str}|{mean_identity}|{std_deviation}\"\n",
    "with open(f\"{save_csv}/SirDataConvVAEModelsCondensation_{max_len}.csv\",'a') as f:   \n",
    "    f.write(result_line + \"\\n\")\n",
    "\n",
    "model_filename = f\"{saved_model_path}/VAE_models/{model_name}.h5\"\n",
    "variational_ae.save_weights(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8df2824-f1e0-4b4c-8be6-f95f4c4d5c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'variational_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cleanup\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m variational_encoder\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m variational_decoder\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m variational_ae\n",
      "\u001b[0;31mNameError\u001b[0m: name 'variational_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "del variational_encoder\n",
    "del variational_decoder\n",
    "del variational_ae\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38c9be86-d011-4364-99ba-42aca8a90472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "53\n",
      "53\n",
      "53\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "for i in range(val1000_fmatrix_embed.shape[0]):\n",
    "    orig = val1000_fmatrix_embed[i] #1024,3\n",
    "    # Determine original (true) sequence length\n",
    "    orig_len = remove_masking(orig[np.newaxis, ...])\n",
    "    orig_trimmed = orig[:orig_len, :]\n",
    "\n",
    "    # Convert to letter sequence\n",
    "    orig_letters = back_to_letters(\n",
    "        np.squeeze(orig_trimmed),\n",
    "        type_of_seq='Original'\n",
    "    )\n",
    "    # Run model 5 times on the same input\n",
    "    all_preds = [variational_ae.predict(orig[np.newaxis, ...], verbose=0)[0] for _ in range(num_repeats)]\n",
    "    # print(all_preds[0],all_preds[0].shape)\n",
    "\n",
    "    # Compute identity scores\n",
    "    scores_i = []\n",
    "    for pred in all_preds:\n",
    "        pred_len = remove_masking(pred[np.newaxis, ...])\n",
    "        pred_trimmed = pred[:pred_len, :]\n",
    "\n",
    "        pred_letters = back_to_letters(\n",
    "            np.squeeze(pred_trimmed),\n",
    "            type_of_seq='Predicted'\n",
    "        )\n",
    "        score = run_needle(pred_letters, orig_letters)\n",
    "        scores_i.append(score)\n",
    "        mean_score = np.mean(scores_i)\n",
    "        identity_scores_list.append(mean_score)\n",
    "        \n",
    "identity_scores_str = ', '.join(map(str, identity_scores_list))\n",
    "# once all batches done:\n",
    "mean_identity = np.mean(identity_scores_list)\n",
    "std_deviation = np.std(identity_scores_list)\n",
    "model_name  = f\"GPConvVAE{max_len}_Condensed{25*codings_size}_{filter_num[0]}_k{filter_size[0]}\"\n",
    "result_line = f\"{model_name}|{val_loss_value}|{identity_scores_str}|{mean_identity}|{std_deviation}\"\n",
    "with open(f\"{save_csv}/GPConvVAEModelsCondensation_{max_len}.csv\",'a') as f:   \n",
    "    f.write(result_line + \"\\n\")\n",
    "\n",
    "model_filename = f\"{saved_model_path}/VAE_models/{model_name}.h5\"\n",
    "variational_ae.save_weights(model_filename)\n",
    "\n",
    "# Cleanup\n",
    "del variational_encoder\n",
    "del variational_decoder\n",
    "del variational_ae\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebfb82-2499-4d9e-8bee-bf5f5ecd5734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
